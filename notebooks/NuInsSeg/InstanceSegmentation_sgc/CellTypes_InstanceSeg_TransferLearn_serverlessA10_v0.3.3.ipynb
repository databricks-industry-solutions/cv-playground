{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df14910a-75bf-47fb-81bc-3a67b64ce77f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Quick Overview: \n",
    "<br> \n",
    "\n",
    "#### YOLO Model\n",
    "[YOLO (You Only Look Once)](https://ieeexplore.ieee.org/document/7780460) is a state-of-the-art, real-time object detection system. It frames object detection as a single regression problem, straight from image pixels to bounding box coordinates and class probabilities. This approach allows YOLO to achieve high accuracy and speed, making it suitable for real-time applications.    \n",
    "\n",
    "<!-- ![Computer Vision Tasks supported by Ultralytics YOLO11](https://github.com/ultralytics/docs/releases/download/0/ultralytics-yolov8-tasks-banner.avif)    -->\n",
    "\n",
    "Offered as part of the [Ultralytics AI framework](https://www.ultralytics.com/), [YOLO11 supports multiple computer vision tasks](https://docs.ultralytics.com/tasks/).    \n",
    "#### Instance Segmentation\n",
    "Recent updates to the YOLO model have introduced capabilities for instance segmentation. [Instance Segmentation](https://docs.ultralytics.com/tasks/segment/#models) not only detects objects but also delineates the exact shape of each object, providing pixel-level masks. \n",
    "![what_is_instance_segmentation](./imgs/what_is_instance_segmentation.png)\n",
    "\n",
    "<!-- ![https://manipulation.csail.mit.edu/segmentation.html](https://manipulation.csail.mit.edu/data/coco_instance_segmentation.jpeg)  -->\n",
    "      \n",
    "This is particularly useful in applications requiring precise object boundaries, for example in medical imaging, autonomous driving, as well as robotics e.g. : \n",
    "<!-- <img src=\"./imgs/instance-segmentation-examples.avif\"\n",
    "     alt=\"YOLO Instance Segmentation Example\"\n",
    "     width=\"800\"\n",
    "     style=\"margin: 200px;\"/>    \n",
    "     `image from https://github.com/ultralytics/docs/releases/download/0/instance-segmentation-examples.avif` -->\n",
    "<!-- ![YOLO Instance Segmentation Example](https://github.com/ultralytics/docs/releases/download/0/instance-segmentation-examples.avif) -->\n",
    "![YOLO Instance Segmentation Example](./imgs/instance-segmentation-examples.avif)\n",
    "`[image from https://github.com/ultralytics/docs/releases/download/0/instance-segmentation-examples.avif]`\n",
    "<br>\n",
    "\n",
    "#### Transfer Learning\n",
    "[Transfer learning](https://www.ultralytics.com/glossary/transfer-learning) involves taking a pre-trained model and fine-tuning it on a new dataset. This approach leverages the knowledge gained from a large dataset and applies it to a specific task, reducing the need for extensive computational resources and training time. In the context of YOLO, transfer learning allows us to adapt the model to new object classes or domains with limited data. \n",
    "<br>\n",
    "\n",
    "#### Note on architecture and segmentation implementation \n",
    "- **YOLO Architecture**: The YOLO architecture consists of convolutional layers followed by fully connected layers, designed to predict bounding boxes and class probabilities directly from the input image.\n",
    "- **Instance Segmentation**: The recent YOLO models incorporate segmentation heads that output pixel-level masks for each detected object, enhancing the model's ability to perform instance segmentation.    \n",
    "<br> \n",
    "\n",
    "For more detailed information, refer to the original YOLO model and the latest research on instance segmentation.    \n",
    "`YOLO Refs:`\n",
    "[`v1`](https://arxiv.org/abs/1506.02640), [`v2`](https://arxiv.org/abs/1612.08242), [`v3`](https://arxiv.org/abs/1804.02767), [`v4`](https://arxiv.org/abs/2004.10934), \n",
    "[`v5`](https://docs.ultralytics.com/models/yolov5/), \n",
    "[`v6`](https://arxiv.org/abs/2209.02976), [`v7`](https://arxiv.org/abs/2207.02696), [`v8`](https://docs.ultralytics.com/models/yolov8/), ... [`v11`](https://docs.ultralytics.com/models/yolo11/#overview) (recent version focused on improved performance and ease of use, used in this example)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b5d025c-1719-478b-b15e-5dca368416e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "---    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae6990dd-34c9-48f8-98de-f2ce271558e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Applying `YOLO_v11` Instance Segmentation within Databricks \n",
    "In the rest of this notebook, we will provide an example of how to leverage [YOLO Instance Segmentation](https://docs.ultralytics.com/tasks/segment/) model in _transfer learning_.     \n",
    " \n",
    "Specifically, we will _finetune_ the `YOLO_v11 Instance Segmentation` model on a new dataset, the [NuInsSeg Dataset](https://github.com/masih4/NuInsSeg/tree/main?tab=readme-ov-file#nuinsseg--a-fully-annotated-dataset-for-nuclei-instance-segmentation-in-he-stained-histological-images), _one of the largest publicly available datasets of segmented nuclei in [H&E-Stained](https://en.wikipedia.org/wiki/H%26E_stain) Histological Images_ (images below of the flow of processes illustrate how these sample data are typically derived).   \n",
    "\n",
    "---     \n",
    "\n",
    "[<img src=\"https://raw.githubusercontent.com/masih4/NuInsSeg/main/git%20images/prepration.png\" width=\"800\"/>](https://raw.githubusercontent.com/masih4/NuInsSeg/main/git%20images/prepration.png)\n",
    "[<img src=\"https://raw.githubusercontent.com/masih4/NuInsSeg/main/git%20images/segmentation%20sample.jpg\" width=\"800\"/>](https://raw.githubusercontent.com/masih4/NuInsSeg/main/git%20images/segmentation%20sample.jpg)\n",
    "\n",
    "---     \n",
    "\n",
    "We will run the _finetuning_ on the Databricks Intelligence platform using [serverless compute](https://www.databricks.com/glossary/serverless-computing). \n",
    "<!-- preprocessed in workspace folder -->\n",
    "To focus our example on the application of YOLO Instance Segmentation, we have already pre-processed the [NuInsSeg Dataset](https://github.com/masih4/NuInsSeg/tree/main?tab=readme-ov-file#nuinsseg--a-fully-annotated-dataset-for-nuclei-instance-segmentation-in-he-stained-histological-images) images in [YOLO format](https://docs.ultralytics.com/datasets/segment/) and included them within the `datasets` folder within the workspace path where this notebook resides.    \n",
    "Along with the `datasets`, we also have information on how the data is organized within the corresponding `data.yaml`.    \n",
    "\n",
    "### What this notebook walks you through:  \n",
    "**[1] _`Default`_ YOLO setup on serverless compute for transfer learning + quick inference    \n",
    "[2] Integration with [Databricks managed MLflow](https://www.databricks.com/product/managed-mlflow) wrt model development tracking and logging + inference using the best checkpoint of the trained YOLO segmentation model.**\n",
    "**This simplified v0.3 notebook demonstrates:**\n",
    "1. **Default YOLO approach** - Quick setup with default Ultralytics settings and its limitations ([a] workspace path limits, [b] minimal MLflow integration)\n",
    "2. **Improved approach addressing [a] & [b]:**\n",
    "   - **Modular utility functions** - Organized in separate modules for better maintainability\n",
    "   - **YOLO setup on serverless compute** - Transfer learning with comprehensive MLflow integration\n",
    "   - **Databricks managed MLflow integration** - Full tracking of parameters, metrics, checkpoints, and artifacts\n",
    "   - **Inference with best checkpoint** - Automated inference and visualization on validation/test sets\n",
    "     \n",
    "For [distributed PyTorch training across multiple GPUS](https://docs.databricks.com/aws/en/machine-learning/train-model/distributed-training/), as well as [registering to Unity Catalog](https://docs.databricks.com/aws/en/machine-learning/manage-model-lifecycle/) and [serving](https://docs.databricks.com/aws/en/machine-learning/model-serving/manage-serving-endpoints) the YOLO model via [MLflow Custom Pyfunc wrapper](https://mlflow.org/docs/2.22.1/traditional-ml/creating-custom-pyfunc), please refer to the linked Databricks reference documentations (and the forthcoming solution accelerator **`cv-playground`** within [Databricks-Industry-Solutions](https://github.com/databricks-industry-solutions).) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d3c45f7-1de5-4e38-9461-22a4985b7767",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Pinned Dependencies"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -q \\\n",
    "    ultralytics==8.3.200 \\\n",
    "    torch==2.6.0+cu124 \\\n",
    "    mlflow==2.21.3 \\\n",
    "    scikit-learn==1.7.2 \\\n",
    "    matplotlib==3.10.7 \\\n",
    "    nvidia-ml-py>=12.0.0 \\\n",
    "    threadpoolctl==3.6.0 \\\n",
    "    --upgrade\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f923c992-930c-46de-83d5-42d500775f9d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libraries"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "import tempfile\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "import torchvision\n",
    "from torchvision import transforms as T\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Import utility modules from utils package\n",
    "# Force reload all utils modules\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Remove all utils modules from cache\n",
    "modules_to_remove = [key for key in sys.modules.keys() if key.startswith('utils')]\n",
    "for module in modules_to_remove:\n",
    "    del sys.modules[module]\n",
    "\n",
    "# Now import fresh\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "\n",
    "from utils import (\n",
    "    # yolo_utils\n",
    "    set_seeds,\n",
    "    path_exists,\n",
    "    get_organized_paths,\n",
    "    setup_yolo_paths, \n",
    "    check_yolo_environment,\n",
    "    get_yolo_paths,\n",
    "    get_inference_output_path,\n",
    "    validate_data_yaml,\n",
    "    get_split_info,\n",
    "    copy_to_uc_volumes_with_yaml,\n",
    "\n",
    "    # mlflow_callbacks\n",
    "    mlflow_epoch_logger,\n",
    "    configure_checkpoint_logging,\n",
    "    copy_training_artifacts,\n",
    "    log_training_artifacts_to_mlflow,\n",
    "    finalize_training_run,\n",
    "\n",
    "    # inference_utils\n",
    "    find_model_by_run_id,\n",
    "    load_model_from_run,\n",
    "    run_inference_with_metrics,\n",
    "    inspect_inference_output,\n",
    "\n",
    "    # visualization_utils\n",
    "    visualize_inference_results,\n",
    "    visualize_predictions_vs_ground_truth,\n",
    "    \n",
    "    # summary_utils\n",
    "    print_inference_summary,\n",
    "    print_multi_split_summary,\n",
    "    export_inference_summary_markdown,\n",
    "\n",
    "    # cache_utils\n",
    "    clear_cuda_cache,\n",
    "    clear_cuda_cache_aggressive,\n",
    "    gpu_status,\n",
    "    clear_all_caches\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9d7ebe0-2906-43f4-9565-9121bc4ca8ec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "RAND seeds"
    }
   },
   "outputs": [],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c2e0071-b347-43d9-9aed-94cc333ac9c4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Catalog-Schema-Volume NAMES"
    }
   },
   "outputs": [],
   "source": [
    "# Replace with your specific catalog and schema etc. names\n",
    "dbutils.widgets.text(\"CATALOG_NAME\", \"<your_catalog_name>\",\"Catalog Name\")\n",
    "dbutils.widgets.text(\"SCHEMA_NAME\",\"<your_schema_name>\",\"Schema Name\")\n",
    "dbutils.widgets.text(\"VOLUME_NAME\",\"<your_project_name>\",\"Volume Name\")\n",
    "\n",
    "#Get the catalog, schema and volume variables\n",
    "CATALOG_NAME = dbutils.widgets.get(\"CATALOG_NAME\")\n",
    "SCHEMA_NAME = dbutils.widgets.get(\"SCHEMA_NAME\")\n",
    "VOLUME_NAME = dbutils.widgets.get(\"VOLUME_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "724f7973-a1c4-47b2-9c07-737bfcdda840",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "CREATE IF NOT EXISTS catalog.schema.volumes"
    }
   },
   "outputs": [],
   "source": [
    "# Create catalog if not exists\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG_NAME}\")\n",
    "\n",
    "# Create schema if not exists\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}\")\n",
    "\n",
    "# Create volume if not exists\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {CATALOG_NAME}.{SCHEMA_NAME}.{VOLUME_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23cf084f-07dc-4c79-b949-578dceddcf5e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "PATH NAMES"
    }
   },
   "outputs": [],
   "source": [
    "## Volumes path prefix\n",
    "VOLUME_PATH = f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}\"\n",
    "\n",
    "PROJECTS_DIR = f\"{VOLUME_PATH}/projects\"\n",
    "PROJECT_PATH = f\"{PROJECTS_DIR}/NuInsSeg\"\n",
    "\n",
    "YOLO_DATA_DIR = f\"{PROJECT_PATH}/yolo_dataset\"\n",
    "\n",
    "# Get the current working directory\n",
    "nb_context = dbutils.notebook.entry_point.getDbutils().notebook().getContext().notebookPath().get()\n",
    "current_path = f\"/Workspace{nb_context}\"\n",
    "WS_PROJ_DIR = '/'.join(current_path.split('/')[:-1]) \n",
    "\n",
    "USER = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "USER_WORKSPACE_PATH = f\"/Users/{USER}\"\n",
    "\n",
    "### Define experiment name\n",
    "project_name = \"yolo_CellTypesNuclei_InstanceSeg_scg\"\n",
    "experiment_name = f\"{USER_WORKSPACE_PATH}/{project_name}\"\n",
    "\n",
    "mlflow.set_experiment(experiment_name)\n",
    "print(f\"Setting experiment name to be {experiment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4917c832-c2e8-422d-9660-6d451440533d",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check paths"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SETUP & CHECK YOLO Paths and Environment\n",
    "# ============================================================================\n",
    "\n",
    "# Setup all paths including Ultralytics config\n",
    "paths = setup_yolo_paths(\n",
    "    project_path=f'/Volumes/{CATLOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}/NuInsSeg',\n",
    "    set_artifacts_path=True,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "664d354b-397f-4fc7-b1e0-27a21cdddca6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "preprocessed DATA in YOLO format in workspace"
    }
   },
   "outputs": [],
   "source": [
    "!ls -lah {WS_PROJ_DIR}/datasets/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05409060-31ce-49f6-87cd-9842b63cbb58",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "data.yaml specifying data paths"
    }
   },
   "outputs": [],
   "source": [
    "!cat data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9eb812d6-fbc4-4fa4-8db7-b010a93284bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### We will first illustrate the `Default` local workspace paths used by Ultralytics.\n",
    "We will re-define these default paths later to illustrate how one would use the preprocessed image datasets ingested and written to UC Vols. and organize the generated assets in model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4d059890-fc05-4964-bc96-a30ea865cee9",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "[Default] Ultralytics PATHS"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import settings\n",
    "\n",
    "# View all default settings\n",
    "print(settings)\n",
    "\n",
    "# datasets_dir\t'/path/to/datasets'\tstr\tThe workspace sub-directory relative to notebook path where the datasets are stored\n",
    "# weights_dir\t'/path/to/weights'\tstr\tThe workspace sub-directory relative to notebook path where the model weights are stored\n",
    "# runs_dir\t'/path/to/runs'\tstr\tThe workspace sub-directory relative to notebook path where the experiment runs are stored\n",
    "\n",
    "## by default:\n",
    "# \"mlflow\": true, # however this isn't exactly logged to the mlflow expt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ebfb9e01-2696-40b9-93d1-d6c4ddf3920a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Run a 'quick' model training to illustrate where data/folder paths are found 'by default' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1be00925-e805-4d3e-8776-6dc2a6002532",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "test writing results to UC Vols"
    }
   },
   "outputs": [],
   "source": [
    "# yolo_default = False # if we have already ran & will go straight to using UC Volumes and mlflow checkpoints\n",
    "\n",
    "yolo_default = True # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3e1907d0-5050-4fa9-9ade-77bb17e0df57",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "\"DEFAULT\" SETTINGS"
    }
   },
   "outputs": [],
   "source": [
    "## if True, we will run the transfer learning using Default YOLO settings \n",
    "\n",
    "if yolo_default:\n",
    "\n",
    "    ## \"DEFAULT\" Quick Start \n",
    "\n",
    "    import torch.distributed as dist\n",
    "    from ultralytics import YOLO\n",
    "\n",
    "    # Initialize the process group | wrt serverless requires specifying world_size and rank\n",
    "    if not dist.is_initialized():\n",
    "        dist.init_process_group(\n",
    "            backend='nccl',  # required for cuda\n",
    "            world_size=1,    # set world_size to 1 for single process\n",
    "            rank=0           # set rank to 0 for single process\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # Transfer the weights from a pretrained model (recommended for training)\n",
    "        model = YOLO(\"yolo11n-seg.pt\") \n",
    "        ## also this will be loaded to the path; if not specified this will be loaded to directory where model training code nb resides WS_PROJ_DIR \n",
    "\n",
    "        results = model.train(                          \n",
    "                                data=f\"{WS_PROJ_DIR}/data.yaml\", ## default settings, YOLO assumes a \"datasets\" dir in directory where model training code nb resides WS_PROJ_DIR\n",
    "                                \n",
    "                                epochs=50, #10, # at least 50 for a decent inference, \n",
    "                                ## reduce epochs to e.g. 10 for a quicker transfer learning training run\n",
    "                                patience=0,  ## setting patience=0 to disable early stopping\n",
    "                                batch=8, ## increase or decrease depending on GPU memory\n",
    "                                imgsz=1024, ## size of NuInsSeg images\n",
    "                                optimizer=\"adam\", ## alternatives e.g. \"adamw\",\"sgd\",\n",
    "                                device=-1, ## most idle GPU\n",
    "                                \n",
    "                                save=True,\n",
    "                                \n",
    "                                name=\"runs/segment/train_sgc\", # workspace path relative to notebook to save run outputs\n",
    "                                project=WS_PROJ_DIR,                                                          \n",
    "                            )\n",
    "        \n",
    "    finally:\n",
    "        # Destroy the process group\n",
    "        dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c4c400a-ab09-4bdb-8711-ac3a14f6ed83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Results saved to path relative to this notebook: `./runs/segment/train_sgc/weights/`     \n",
    "*NB: If you retrain with same configs -- addiitonal training paths and subdirs will be added to `./runs/segment/train_sgc{#}/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96ebf1be-221b-4423-b498-35135f60c430",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "list workspace weights folder path"
    }
   },
   "outputs": [],
   "source": [
    "!ls -lah ./runs/segment/train_sgc/weights/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15e7ade5-f6bf-4b7d-a454-19007ea519b2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Image Results"
    }
   },
   "outputs": [],
   "source": [
    "if yolo_default==True:\n",
    "  display(Image(filename=\"runs/segment/train_sgc/results.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4f50066-85ad-4f6f-884e-abce5ffc7448",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Quick Inference with default YOLO framework + Workspace datapath best weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47c7b8f3-c5db-4c41-a745-9fd3ef55a0fd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load model with WS best trained weights and make inference predictions"
    }
   },
   "outputs": [],
   "source": [
    "# Define the project directory\n",
    "test_data_path = f\"{WS_PROJ_DIR}/datasets/test/images\"\n",
    "\n",
    "# Load the trained YOLO model\n",
    "model = YOLO(\"./runs/segment/train_sgc/weights/best.pt\")\n",
    "\n",
    "# Load test data\n",
    "print(test_data_path)\n",
    "\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(test_data_path):\n",
    "    raise FileNotFoundError(f\"The directory {test_data_path} does not exist.\")\n",
    "\n",
    "test_images = [os.path.join(test_data_path, img) for img in os.listdir(test_data_path) if img.endswith('.png')]\n",
    "\n",
    "# Randomly select 25 images\n",
    "selected_images = random.sample(test_images, 25)\n",
    "\n",
    "# Resize images to a smaller size\n",
    "resized_images = []\n",
    "for img_path in selected_images:\n",
    "    img = cv2.imread(img_path)\n",
    "    resized_img = cv2.resize(img, (640, 640))  # Resize to 640x640 or any desired size\n",
    "    resized_images.append(resized_img)\n",
    "\n",
    "# Batch Predict using the loaded model\n",
    "inferece_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "results = model.predict(resized_images,\n",
    "                        save=True,  # Save predictions to disk\n",
    "                        project=\"./runs/predict\",  # Base directory on workspace path for saving\n",
    "                        name=f\"test_inference_{inferece_timestamp}\"    # Subdirectory name\n",
    "                       )\n",
    "\n",
    "\n",
    "# Plot 5x5 grid of test images with predictions\n",
    "fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "for img, result, ax in zip(resized_images, results, axes):\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])  # Flatten the list before mapping to int\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 255, 255), 2)\n",
    "        # cv2.putText(img, f\"{box.cls}\", (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 255, 255), 2)\n",
    "    ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "## NB processing speed is much faster after the initial first inference ~50ms vs ~5ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b06899ee-9c25-461d-8a2f-1af5aaa3d80c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using the `Default` Ultralytics `model.predict()` on a random sample of test images we observe the relative efficiency the inference can be performed on YOLO-formatted test images.\n",
    "Depending on the length of training epochs and different batch sizes, inference performance can further improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f8e0c06-db7f-40ce-96ed-68b9ae4227b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6d3a07e-845d-4020-b65e-d54037bd315f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Overall, it is quick to set up training using default YOLO setttings as long as images are preprocessed and formatted in [YOLO format](https://docs.ultralytics.com/datasets/detect/#which-datasets-are-supported-by-ultralytics-yolo-for-object-detection).    \n",
    "Model training and validation using YOLO-based metrics tracking within workspace path are provided \"out-of-the-box\".  \n",
    "However, there is minimal MLflow integration.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb1f0bed-28cb-4dd6-846f-14d536dfcf42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Limitations of `Default` Ultralytics `settings`: \n",
    "- **[a] Workspace folder path with files written there by default**\n",
    "  - Workspace [limitations](https://docs.databricks.com/aws/en/files/workspace#limitations) exist and files are subjected to [500mb filesize limits](https://docs.databricks.com/aws/en/files/workspace#file-size-limit)\n",
    "  - Training `runs` and `results` currently saved to `./runs/segment/train_sgc{#}`\n",
    "  - Ideally it would be good to update and/or write to UC volumes project-related paths e.g. \n",
    "    - location where `yolo_dataset` was originally downloaded and preprocessed for yolo-formatted image reference\n",
    "    - organize `runs` by `run_name` and `datetime`\n",
    "- **[b] Not Databricks-managed MLflow logged or tracked**   \n",
    "  - `experiment_id`; `experiment_name`: (when not specified, the default \"Ultralytics\" is set e.g. on Classic MLdbr compute)\n",
    "  - `run_id`; `run_name`\n",
    "  - `model` metrics -- not logged to MLflow\n",
    "  - `system` metrics -- GPU usage is shown in the training printouts but not logged to MLFlow\n",
    "  - `checkpointing` is missing and not best inference meal is racked \n",
    "- **[c] Model not registered as UC model**\n",
    "  - Requires first defining the YOLO model as [MLflow Custom Pyfunc](https://mlflow.org/docs/2.22.1/traditional-ml/creating-custom-pyfunc) with load-context linked to artifacth paths before logging to MLflow and subsequently registered a UC model ([Databricks ref](https://docs.databricks.com/aws/en/machine-learning/model-serving/deploy-custom-python-code))\n",
    "- **[d] GPU resources not fully leveraged where multiple GPUs exsits** (e.g. in Classic MLdbr and Serverless -- forthcoming)\n",
    "    - single node -- multiple workers; \n",
    "    - multiple nodes -- multiple workers\n",
    "    \n",
    "     \n",
    "For a fuller integration with the Databricks ecosystem would require a few additional tweaks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "421f52a0-95dc-4993-b65a-83d13f99768e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cda23eac-8955-4bb7-a484-bea5691ca11b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### We will address [a] & [b] in this section:\n",
    "[c] and [d] will be addressed in a separate notebook for distributed DL training using either Classic and/or Serverless GPU Compute (forthcoming)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f66c8f4c-94bd-4a65-a3f2-156eeb3483df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Data Preparation: Copy YOLO Images to Unity Catalog Volumes\n",
    "To make sure we have sufficient space and paths to organize our training outputs, MLflow tracking, and logging, we will copy our workspace YOLO formatted data to UC Volumes. \n",
    "_The [NuInsSeg data](https://github.com/masih4/NuInsSeg/tree/main?tab=readme-ov-file#nuinsseg--a-fully-annotated-dataset-for-nuclei-instance-segmentation-in-he-stained-histological-images), while not huge in size, takes about 5-10 mins for the copying to UC Volumes. Ideally the data is downloaded to UC Vols and the preprocessed versions are updated in UC via medallion ETL. For the simplicity of this example we make them available via the workspace path as a start._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1690d1f-2a07-4ec5-b590-b05e2a917700",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "YOLO_DATA_UCVol_path"
    }
   },
   "outputs": [],
   "source": [
    "## Specify the UC Volumes destination path for the YOLO dataset\n",
    "YOLO_DATA_UCVol_path = f'{PROJECT_PATH}/yolo_dataset_on_vols'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "200c37e6-34ff-4b8c-a916-803df51b93c0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "copy datasets to UC Vols (if needed)"
    }
   },
   "outputs": [],
   "source": [
    "## Execute the copy ~8mins | leave commented out if already done else uncomment & run\n",
    "data_yaml_path = copy_to_uc_volumes_with_yaml(WS_PROJ_DIR, YOLO_DATA_UCVol_path)\n",
    "\n",
    "##NB: rsync will attempt to make copy -- you may see initial errors/warnings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41060286-b341-46ca-803d-14a22ee809fc",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check for required data/configs/paths"
    }
   },
   "outputs": [],
   "source": [
    "# Verify YOLO training requirements from UC Vols are met\n",
    "status = check_yolo_environment(verbose=True, create_missing=True)\n",
    "\n",
    "if not status['ready']:\n",
    "    raise RuntimeError(\"Environment not ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9c182217-4f5c-4194-a9d9-90ad29403878",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Specify & Organize Training Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11fcbf73-a7e1-408d-a510-47036ce6cdfe",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Update settings"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import settings\n",
    "\n",
    "# Update setting specirically for datasets_dir\n",
    "settings.update({\"datasets_dir\": f\"{YOLO_DATA_UCVol_path}\"})\n",
    "print(settings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbb3bba6-be62-4842-a5d6-9aa4b1328c57",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Additional Paths for PyTorch Training"
    }
   },
   "outputs": [],
   "source": [
    "# Config project structure directory under UC\n",
    "PROJECT_training_runs = f'{PROJECT_PATH}/training_runs_sgc/'\n",
    "os.makedirs(PROJECT_training_runs, exist_ok=True)\n",
    "\n",
    "PROJECT_yolo_model = f'{PROJECT_PATH}/yolo_model_sgc/'\n",
    "os.makedirs(PROJECT_yolo_model, exist_ok=True)\n",
    "\n",
    "# for cache related to ultralytics\n",
    "os.environ['ULTRALYTICS_CACHE_DIR'] = PROJECT_yolo_model\n",
    "\n",
    "\n",
    "## ephemeral project location on VM, required for Appending operation during training.\n",
    "# tmp_project_location = f\"/local_disk0/tmp/nuinsseg/\" # not consistently accessible via severless but much faster on classic compute cf /tmp/\n",
    "# os.makedirs(tmp_project_location, exist_ok=True)\n",
    "\n",
    "# Serverless provides writable temp space\n",
    "tmp_project_location = os.path.join(tempfile.gettempdir(), \"nuinsseg\")\n",
    "print(f\"Temp project location: {tmp_project_location}\")\n",
    "os.makedirs(tmp_project_location, exist_ok=True)\n",
    "\n",
    "\n",
    "# Make tmp_project_location available to callbacks\n",
    "import builtins\n",
    "builtins.tmp_project_location = tmp_project_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f9c07231-8b7b-4710-a526-3c7020b9e2db",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "path permissions check!"
    }
   },
   "outputs": [],
   "source": [
    "!ls -lah {tmp_project_location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5c152ba-2adc-4ad8-bbbb-998d9634f807",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check gpu status"
    }
   },
   "outputs": [],
   "source": [
    "%sh nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfa14ef4-27d2-4bbf-a5b3-6ca7e0ffbdf4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "check cuda availability"
    }
   },
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "927d927a-0694-4dfb-bc40-2a5d5ea25d23",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Load model and check device"
    }
   },
   "outputs": [],
   "source": [
    "model = YOLO(f\"{PROJECT_yolo_model}/yolo11n-seg.pt\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "\n",
    "# If not on CUDA, move to CUDA\n",
    "if next(model.parameters()).device.type != 'cuda':\n",
    "    model.to('cuda')\n",
    "    print(f\"Moved model to: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b21548d9-64fe-4f0f-bf50-af2c734342e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Transfer Learning: Run on Serverless GPU with MLflow Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4260645f-0fb4-4ccd-ab87-df70c35a8db7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Training Configuration + MLflow Callback"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# Clean up any active runs\n",
    "if mlflow.active_run():\n",
    "    print(f\"Ending active run: {mlflow.active_run().info.run_id}\")\n",
    "    mlflow.end_run()\n",
    "\n",
    "if not dist.is_initialized():\n",
    "    dist.init_process_group(backend=\"nccl\", world_size=1, rank=0)\n",
    "\n",
    "# Checkpoint logging configuration \n",
    "CHECKPOINT_LOG_FREQUENCY = 10 #1 #10 (for larger n_epochs training) # you can specify to use e.g. n_epochs/divisor\n",
    "configure_checkpoint_logging(frequency=CHECKPOINT_LOG_FREQUENCY, log_best=True, log_final=True, log_first=True)\n",
    "\n",
    "# Get experiment\n",
    "experiment = mlflow.get_experiment_by_name(experiment_name)\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "if experiment is None:    \n",
    "    print(f\"Creating experiment: {experiment_name}\")\n",
    "    experiment_id = mlflow.create_experiment(name=experiment_name)\n",
    "else:\n",
    "    print(f\"Reusing experiment_name: {experiment_name} | experiment_id: {experiment.experiment_id}\")\n",
    "    experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de1a5f3f-14d6-42d7-9708-bc5d9c2d5eb6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Training with callback and MLflow run + minimal plots/saving"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 50 #10  # For quick testing use e.g. 5-10; at least 50 epochs for better inference performance | Adjust as needed | 50 epochs + batch=8 : 1hr50mins\n",
    "batch_sz = 8  # Adjust based on GPU memory\n",
    "\n",
    "try:\n",
    "    with mlflow.start_run(\n",
    "        experiment_id=experiment_id,\n",
    "        run_name=f\"yolo_training_{timestamp}\",\n",
    "        log_system_metrics=True,\n",
    "    ) as run:\n",
    "\n",
    "        # Get organized paths\n",
    "        run_paths = get_organized_paths(run.info.run_id, timestamp, PROJECT_PATH)\n",
    "        \n",
    "        # Create all directories\n",
    "        for path_key, path_value in run_paths.items():\n",
    "            if path_key != 'base':\n",
    "                os.makedirs(path_value, exist_ok=True)\n",
    "        \n",
    "        print(f\"Organized paths:\")\n",
    "        print(f\"  Base: {run_paths['base']}\")\n",
    "        print(f\"  Train: {run_paths['train']}\")\n",
    "        print(f\"  Weights: {run_paths['train_weights']}\")\n",
    "        \n",
    "        # Make run_paths available globally for inference\n",
    "        builtins.current_run_paths = run_paths\n",
    "        builtins.YOLO_DATA_UCVol_path = YOLO_DATA_UCVol_path\n",
    "        \n",
    "        # Load model\n",
    "        model = YOLO(f\"{PROJECT_PATH}/yolo_model_sgc/yolo11n-seg.pt\")\n",
    "        model.to(\"cuda\")\n",
    "        \n",
    "        # Log parameters\n",
    "        mlflow.log_params({\n",
    "            \"model_name\": \"yolo11n-seg\",\n",
    "            \"epochs\": n_epochs,\n",
    "            \"batch_size\": batch_sz,\n",
    "            \"image_size\": 1024,\n",
    "            \"optimizer\": \"adam\",\n",
    "            \"checkpoint_log_frequency\": CHECKPOINT_LOG_FREQUENCY,\n",
    "            \"training_timestamp\": timestamp,\n",
    "            \"artifacts_base_path\": run_paths['base'],\n",
    "        })\n",
    "        \n",
    "        # Register callback\n",
    "        model.add_callback(\"on_fit_epoch_end\", mlflow_epoch_logger)\n",
    "        \n",
    "        # TRAIN\n",
    "        print(f\"\\nStarting training: yolo_training_{timestamp}\")\n",
    "        print(f\"Epochs: {n_epochs}, Batch: {batch_sz}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        model.train(            \n",
    "            data=os.path.join(YOLO_DATA_UCVol_path, \"data.yaml\"),\n",
    "            epochs=n_epochs, \n",
    "            batch=batch_sz, \n",
    "            imgsz=1024,\n",
    "            workers=0, ## A10 SGC has no multithreaded workers\n",
    "            project=tmp_project_location,\n",
    "            name=\"yolo_training\",\n",
    "            exist_ok=True,\n",
    "            optimizer=\"adam\",\n",
    "            device=0,          # Explicit instead of selecting idle GPU e.g. device = -1\n",
    "            val=True,\n",
    "            plots=False,       # Disable plots during training\n",
    "            save=True,\n",
    "            save_period=-1,    # Only save last/best wrt YOLO framework -- MLflow logging is done separately + callbacks\n",
    "            # save_weights=True, # Save weights for each epoch            \n",
    "        )\n",
    "        \n",
    "        # Copy artifacts to UC Volumes\n",
    "        copy_training_artifacts(tmp_project_location, run_paths)\n",
    "        \n",
    "        # Log artifacts to MLflow\n",
    "        data_yaml_path = os.path.join(YOLO_DATA_UCVol_path, \"data.yaml\")\n",
    "        log_training_artifacts_to_mlflow(run_paths, data_yaml_path)\n",
    "        \n",
    "        # Finalize training run with metrics and summary\n",
    "        finalize_training_run(run, timestamp, n_epochs, batch_sz, run_paths)\n",
    "        \n",
    "        # Store for inference use\n",
    "        global current_run_paths\n",
    "        current_run_paths = run_paths\n",
    "        \n",
    "        # Reset callback state for next run\n",
    "        for attr in ['best_fitness', 'best_epoch', 'checkpoints_logged']:\n",
    "            if hasattr(mlflow_epoch_logger, attr):\n",
    "                delattr(mlflow_epoch_logger, attr)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n{'='*70}\\nTRAINING FAILED\\n{'='*70}\")\n",
    "    print(f\"Error: {e}\\n{'='*70}\")\n",
    "    \n",
    "    # Log error to MLflow if possible\n",
    "    try:\n",
    "        mlflow.log_param(\"training_error\", str(e))\n",
    "        mlflow.set_tag(\"training_status\", \"failed\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Clean up callback state\n",
    "    for attr in ['best_fitness', 'best_epoch', 'checkpoints_logged']:\n",
    "        if hasattr(mlflow_epoch_logger, attr):\n",
    "            delattr(mlflow_epoch_logger, attr)\n",
    "    \n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6fbd4aa-5102-4237-8bfa-5ad6f2080642",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Note:** \n",
    "Slower training via SGC with comprehensive MLFlow tracking/checkpointing/plots-saving (may not be required for quick testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad11bae6-6ec1-4c5c-bddb-dc41128cab30",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Get run_id"
    }
   },
   "outputs": [],
   "source": [
    "# run_id = \"<manually add from previous run>\"\n",
    "\n",
    "run_id = run.info.run_id\n",
    "print(f\"Run ID: {run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d9f1818-1390-4b6d-85de-60d4adb1c19f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b0d071ca-166d-4f71-835f-adca34fd2d45",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Post-Training: Validation (optional) + Test Inference + Visualization\n",
    "With the model trained and checkpoints saved, we can now:\n",
    "1. Load the best model from the training run\n",
    "2. Run inference on (validation and) test sets\n",
    "3. Where labels exist for datasets, we can    \n",
    "  a. Calculate comprehensive metrics (mAP, precision, recall, fitness);   \n",
    "  b. Compare predictions against ground truth  \n",
    "4. Visualize predictions with customizable overlays\n",
    "5. Generate summary reports.  \n",
    "All inference results are automatically logged to MLflow and saved to Unity Catalog volumes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a69907f7-df71-4d98-aea5-6e9912efdb26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2da65c89-63b2-4934-a376-72b4613980b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**!!! NB:** We may have to restart the compute, run the relevant setups and paths (without retraining) for Inferencing due to A10 CUDA OOM; alternatively, select `device='cpu'` in the input args.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92ae2582-94a3-4cfd-b4b5-fcdd9f66c791",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Run {Val} or Test Inference + Metrics"
    }
   },
   "outputs": [],
   "source": [
    "## Clear cache before starting\n",
    "clear_all_caches()\n",
    "torch.cuda.empty_cache()\n",
    "gpu_status() ## need at least ~5-10gigs\n",
    "\n",
    "# Run inference on test split with validation\n",
    "test_summary = run_inference_with_metrics(\n",
    "    run_id=run_id,\n",
    "    split='test',\n",
    "    has_labels=True, ## in this dataset test split has labels ## alternatively has_labels=False, # test -- will not run validation\n",
    "    validate_config=True,  # Validates data.yaml before running\n",
    "    log_to_mlflow=True,\n",
    "    skip_existing_params=True,    \n",
    "    # debug=True,  #  Enable debug output # test without debug\n",
    "    device='cuda', # 'auto' | 'cpu' in case of cuda OOM    \n",
    "    batch_size=8 # reduce if necessary \n",
    ")\n",
    "\n",
    "# Inspect the output\n",
    "# inspect_inference_output(test_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e06057ea-940c-4b77-be4d-19da187bd996",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Test Inference Summary"
    }
   },
   "outputs": [],
   "source": [
    "print_inference_summary(test_summary, include_paths=True, include_performance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1b7db4b-46c7-4ba9-8882-01c8c6f87347",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Visualize Test Results - Boxes Only"
    }
   },
   "outputs": [],
   "source": [
    "## Clear cache before starting\n",
    "clear_all_caches()\n",
    "torch.cuda.empty_cache()\n",
    "gpu_status() \n",
    "\n",
    "fig = visualize_inference_results(\n",
    "    test_summary,\n",
    "    num_samples=25, # update as appropriate\n",
    "    show_boxes=True,\n",
    "    show_masks=False,\n",
    "    show_labels=False,\n",
    "    show_conf=False,\n",
    "    box_color=(255, 255, 255),\n",
    "    figsize=(10,10),\n",
    "    save_figure=True,    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc5fa3c4-fae1-42cc-87ba-b116141800b7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "test | no labels"
    }
   },
   "outputs": [],
   "source": [
    "## Clear cache before starting\n",
    "clear_all_caches()\n",
    "torch.cuda.empty_cache()\n",
    "gpu_status() \n",
    "\n",
    "# Test predict mode (no labels)\n",
    "test_predict_summary = run_inference_with_metrics(\n",
    "    run_id=run_id,\n",
    "    split='test',\n",
    "    has_labels=False,  # Force predict mode\n",
    "    validate_config=True,\n",
    "    log_to_mlflow=True,\n",
    "    skip_existing_params=True,\n",
    "    # debug=True,  \n",
    "    device='cpu', # slower per image but avoids CUDA OOM\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96579b80-ff84-4110-bd18-f9a023f00a21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Summary\n",
    "------------------------------------------------------------------ \n",
    "In this notebook we demonstrated how to leverage the YOLO instance segmentation model on a custom nuclei dataset preprocessed in YOLO format and saved on Unity Catalog volumes.\n",
    "\n",
    "Depending on the number of training epochs and other parameters, the inference results may yield better cell nuclei segmentations. The logged metrics and visualizations can help guide the focus of finetuning.\n",
    "\n",
    "Future work and extensions: Distributed training (multi-GPU), as well as logging the finetuned YOLO model as a MLflow Custom Pyfunc for Unity Catalog registration, and/or serving as an endpoint for downstream applications.\n",
    "\n",
    "#### What We Built\n",
    "\n",
    "We enhanced MLflow tracking and checkpointing for YOLO training workflows within Databricks with the following features:   \n",
    "\n",
    "**Native Databricks Managed MLflow Integration:**\n",
    "We used MLflow's tracking API to log parameters, metrics, and artifacts (including model checkpoints) directly from within the training loop via custom callbacks, leveraging Databricks' built-in MLflow support for seamless experiment management and centralized artifact storage.   \n",
    "\n",
    "**Custom Epoch-Level Callback for Comprehensive Tracking:**\n",
    "A custom `mlflow_epoch_logger` callback was implemented to capture and log training/validation metrics after each epoch, providing detailed visibility into model performance throughout training. This goes beyond YOLO's default CSV-based logging by providing structured, queryable metrics in MLflow.   \n",
    "\n",
    "**Configurable Checkpoint Logging:**\n",
    "The callback supports flexible checkpoint logging strategies:\n",
    "- Log first epoch (baseline)\n",
    "- Log final epoch (completion)\n",
    "- Log best model (based on fitness metric)\n",
    "- Log periodic checkpoints (configurable frequency, e.g., every 10 epochs)\n",
    "This provides fine-grained model versioning and recovery options while balancing storage efficiency.   \n",
    "\n",
    "**`Best Model` Tracking:**\n",
    "The callback monitors validation fitness (weighted combination of mAP50 and mAP50-95) and automatically logs the best-performing model checkpoint to MLflow, ensuring easy access to the optimal model for deployment or further analysis.   \n",
    "\n",
    "<!-- **Resume Training Support:**\n",
    "Helper functions (`setup_resume()`, `get_resume_checkpoint()`) enable resuming training from any saved checkpoint, restoring both model state and callback tracking variables (best fitness, best epoch, checkpoint count) for seamless continuation of interrupted training runs.    -->\n",
    "\n",
    "**Organized Artifact Management:**\n",
    "Training artifacts are organized in a structured directory hierarchy on Unity Catalog volumes:   \n",
    "\n",
    "```\n",
    "\n",
    "/Volumes/catalog/schema/volume/ \n",
    " run_YYYYMMDD_HHMMSS_<run_id>/ \n",
    " train/ \n",
    "  weights/ \n",
    "  checkpoints/ \n",
    "  [plots, logs, results.csv] \n",
    " val/\n",
    " test/\n",
    "```\n",
    "#### Overall\n",
    "This approach provides a **production-ready, reproducible, and collaborative** deep learning workflow for YOLO training within the Databricks ecosystem. While it adds some overhead compared to vanilla YOLO, it delivers significant value through:\n",
    "1. **Comprehensive experiment tracking** - All metrics, parameters, and artifacts in one place\n",
    " : within MLflow UI and UC Volumes path.   \n",
    "2. **Reproducibility** - Easy to recreate any training run from logged artifacts\n",
    "3. **Collaboration** - Centralized storage and tracking accessible to entire team\n",
    "4. **Governance** - Unity Catalog integration for access control and lineage\n",
    "5. **Flexibility** - Compare experiments, deploy best models. \n",
    "<!-- 5. **Flexibility** - Resume training (helperfuncs included), compare experiments, deploy best models.  -->\n",
    "\n",
    "The trade-off between performance overhead and operational benefits makes this approach well-suited for **production ML workflows** where reproducibility, collaboration, and governance are priorities."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "CellTypes_InstanceSeg_TransferLearn_serverlessA10_v0.3.3",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
