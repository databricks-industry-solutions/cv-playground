{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7952e7f-0638-48f5-9e76-7641efc46db8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This is a reference example of how one could go about auto-detecting and configurating resources -- but this requires some testing wrt your model, data, and access to compute etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea3da6fd-95b6-4346-b338-214ee132ce0c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "example (1)"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CLUSTER RESOURCE DETECTION & AUTO-CONFIGURATION\n",
    "# ============================================================\n",
    "import torch\n",
    "from pyspark.sql import SparkSession\n",
    "from typing import Dict\n",
    "\n",
    "def detect_and_configure_resources() -> Dict:\n",
    "    \"\"\"Detect cluster resources and return optimized training configuration.\"\"\"\n",
    "    config = {\n",
    "        'num_gpus_per_node': 0,\n",
    "        'num_workers': 0,\n",
    "        'total_nodes': 1,\n",
    "        'total_gpus': 0,\n",
    "        'use_gpu': False,\n",
    "        'cuda_available': torch.cuda.is_available(),\n",
    "        'recommended_batch_size': 32, # heuristics \n",
    "        'recommended_num_workers': 4, # \n",
    "        'distributor_num_processes': 1,\n",
    "        'distributor_local_mode': True\n",
    "    }\n",
    "    \n",
    "    # GPU detection\n",
    "    if torch.cuda.is_available():\n",
    "        config['num_gpus_per_node'] = torch.cuda.device_count()\n",
    "        config['use_gpu'] = True\n",
    "        \n",
    "        # Recommend batch size based on GPU memory\n",
    "        try:\n",
    "            props = torch.cuda.get_device_properties(0)\n",
    "            memory_gb = props.total_memory / (1024**3)\n",
    "            \n",
    "            if memory_gb >= 40:    # A100/H100\n",
    "                config['recommended_batch_size'] = 128\n",
    "            elif memory_gb >= 24:  # A10/RTX 4090\n",
    "                config['recommended_batch_size'] = 64\n",
    "            elif memory_gb >= 16:  # V100/T4\n",
    "                config['recommended_batch_size'] = 32\n",
    "            else:\n",
    "                config['recommended_batch_size'] = 16\n",
    "        except:\n",
    "            config['recommended_batch_size'] = 32\n",
    "    \n",
    "    # Cluster size detection\n",
    "    try:\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        sc = spark.sparkContext\n",
    "        \n",
    "        executors = sc._jsc.sc().statusTracker().getExecutorInfos()\n",
    "        config['num_workers'] = len(executors) - 1\n",
    "        config['total_nodes'] = config['num_workers'] + 1\n",
    "        \n",
    "        # Recommend dataloader workers based on cluster size\n",
    "        # Heuristics: 2-[4]-8 workers per GPU, capped at 8\n",
    "        if config['use_gpu']:\n",
    "            config['recommended_num_workers'] = min(4 * config['num_gpus_per_node'], 8)\n",
    "        else:\n",
    "            config['recommended_num_workers'] = 4\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not detect cluster size: {e}\")\n",
    "        config['num_workers'] = 0\n",
    "        config['total_nodes'] = 1\n",
    "        config['recommended_num_workers'] = 4\n",
    "    \n",
    "    # Calculate total GPUs and distributor config\n",
    "    config['total_gpus'] = config['num_gpus_per_node'] * config['total_nodes']\n",
    "    \n",
    "    if config['use_gpu']:\n",
    "        config['distributor_num_processes'] = config['total_gpus']\n",
    "        config['distributor_local_mode'] = config['total_nodes'] == 1\n",
    "    else:\n",
    "        config['distributor_num_processes'] = max(config['num_workers'], 1)\n",
    "        config['distributor_local_mode'] = config['num_workers'] == 0\n",
    "    \n",
    "    return config\n",
    "\n",
    "# Detect resources\n",
    "CLUSTER_RESOURCES = detect_and_configure_resources()\n",
    "CLUSTER_RESOURCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb8c4736-0e1f-44db-99c7-5d1f345eda3e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "example (2)"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# BATCH SIZE AND NUM_WORKERS DETERMINATION LOGIC\n",
    "# ============================================================\n",
    "from typing import Dict\n",
    "import torch\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "def detect_and_configure_resources() -> Dict:\n",
    "    \"\"\"Detect cluster resources and return optimized training configuration.\"\"\"\n",
    "    config = {\n",
    "        'num_gpus_per_node': 0,\n",
    "        'num_workers': 0,\n",
    "        'total_nodes': 1,\n",
    "        'total_gpus': 0,\n",
    "        'use_gpu': False,\n",
    "        'cuda_available': torch.cuda.is_available(),\n",
    "        'recommended_batch_size': 32,  # fallback\n",
    "        'recommended_num_workers': 4,  # fallback\n",
    "        'distributor_num_processes': 1,\n",
    "        'distributor_local_mode': True,\n",
    "        'gpu_memory_gb': 0.0,\n",
    "        'gpu_name': None\n",
    "    }\n",
    "    \n",
    "    # ============================================================\n",
    "    # BATCH SIZE DETERMINATION - Based on GPU Memory\n",
    "    # ============================================================\n",
    "    if torch.cuda.is_available():\n",
    "        config['num_gpus_per_node'] = torch.cuda.device_count()\n",
    "        config['use_gpu'] = True\n",
    "        \n",
    "        try:\n",
    "            # Get GPU properties\n",
    "            props = torch.cuda.get_device_properties(0)\n",
    "            memory_gb = props.total_memory / (1024**3)\n",
    "            gpu_name = props.name\n",
    "            \n",
    "            config['gpu_memory_gb'] = round(memory_gb, 2)\n",
    "            config['gpu_name'] = gpu_name\n",
    "            \n",
    "            # Batch size recommendations based on empirical testing\n",
    "            # These are ~conservative estimates for image classification with ResNet/MobileNet\n",
    "            if memory_gb >= 80:      # H100 (80GB)\n",
    "                config['recommended_batch_size'] = 256\n",
    "            elif memory_gb >= 40:    # A100 (40GB/80GB)\n",
    "                config['recommended_batch_size'] = 128\n",
    "            elif memory_gb >= 24:    # A10G (24GB), RTX 4090 (24GB)\n",
    "                config['recommended_batch_size'] = 64\n",
    "            elif memory_gb >= 16:    # V100 (16GB), T4 (16GB)\n",
    "                config['recommended_batch_size'] = 32\n",
    "            elif memory_gb >= 12:    # T4 (12GB variant)\n",
    "                config['recommended_batch_size'] = 24\n",
    "            elif memory_gb >= 8:     # RTX 2080 (8GB)\n",
    "                config['recommended_batch_size'] = 16\n",
    "            else:                    # Smaller GPUs\n",
    "                config['recommended_batch_size'] = 8\n",
    "                \n",
    "            print(f\"  GPU: {gpu_name} ({memory_gb:.1f}GB)\")\n",
    "            print(f\"  Recommended batch size: {config['recommended_batch_size']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Warning: Could not detect GPU memory: {e}\")\n",
    "            config['recommended_batch_size'] = 32  # Safe default\n",
    "    else:\n",
    "        # CPU-only training - use smaller batch size\n",
    "        config['recommended_batch_size'] = 16\n",
    "        print(f\"  CPU-only mode: Using batch size {config['recommended_batch_size']}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # NUM_WORKERS DETERMINATION - Based on CPU cores and GPUs\n",
    "    # ============================================================\n",
    "    try:\n",
    "        spark = SparkSession.builder.getOrCreate()\n",
    "        sc = spark.sparkContext\n",
    "        \n",
    "        executors = sc._jsc.sc().statusTracker().getExecutorInfos()\n",
    "        config['num_workers'] = len(executors) - 1\n",
    "        config['total_nodes'] = config['num_workers'] + 1\n",
    "        \n",
    "        # Get CPU core count\n",
    "        import multiprocessing\n",
    "        cpu_cores = multiprocessing.cpu_count()\n",
    "        \n",
    "        if config['use_gpu']:\n",
    "            # GPU training: num_workers for DataLoader\n",
    "            # Rule of thumb: 4 workers per GPU, but cap based on CPU cores\n",
    "            # Leave some cores for system/other processes\n",
    "            \n",
    "            workers_per_gpu = 4  # Standard/General recommendation\n",
    "            total_workers_needed = workers_per_gpu * config['num_gpus_per_node']\n",
    "            \n",
    "            # Cap at 75% of available cores to avoid oversubscription\n",
    "            max_workers = int(cpu_cores * 0.75)\n",
    "            \n",
    "            # Also cap at 8 per GPU (diminishing returns beyond this)\n",
    "            absolute_max = 8 * config['num_gpus_per_node']\n",
    "            \n",
    "            config['recommended_num_workers'] = min(\n",
    "                total_workers_needed,\n",
    "                max_workers,\n",
    "                absolute_max\n",
    "            )\n",
    "            \n",
    "            # Ensure at least 2 workers per GPU\n",
    "            config['recommended_num_workers'] = max(\n",
    "                config['recommended_num_workers'],\n",
    "                2 * config['num_gpus_per_node']\n",
    "            )\n",
    "            \n",
    "            print(f\"  CPU cores: {cpu_cores}\")\n",
    "            print(f\"  GPUs per node: {config['num_gpus_per_node']}\")\n",
    "            print(f\"  Recommended DataLoader workers: {config['recommended_num_workers']}\")\n",
    "            print(f\"    (4 workers/GPU, capped at {max_workers} based on {cpu_cores} cores)\")\n",
    "            \n",
    "        else:\n",
    "            # CPU training: fewer workers to avoid thread contention\n",
    "            # Use 50% of cores for data loading, rest for computation\n",
    "            config['recommended_num_workers'] = max(2, int(cpu_cores * 0.5))\n",
    "            \n",
    "            print(f\"  CPU cores: {cpu_cores}\")\n",
    "            print(f\"  Recommended DataLoader workers: {config['recommended_num_workers']}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"  Warning: Could not detect cluster configuration: {e}\")\n",
    "        # Fallback defaults\n",
    "        if config['use_gpu']:\n",
    "            config['recommended_num_workers'] = 4 * config['num_gpus_per_node']\n",
    "        else:\n",
    "            config['recommended_num_workers'] = 4\n",
    "    \n",
    "    # ============================================================\n",
    "    # ADDITIONAL OPTIMIZATIONS\n",
    "    # ============================================================\n",
    "    \n",
    "    # Calculate total GPUs and distributor config\n",
    "    config['total_gpus'] = config['num_gpus_per_node'] * config['total_nodes']\n",
    "    \n",
    "    if config['use_gpu']:\n",
    "        config['distributor_num_processes'] = config['total_gpus']\n",
    "        config['distributor_local_mode'] = config['total_nodes'] == 1\n",
    "    else:\n",
    "        config['distributor_num_processes'] = max(config['num_workers'], 1)\n",
    "        config['distributor_local_mode'] = config['num_workers'] == 0\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# e.g. MODEL-SPECIFIC BATCH SIZE RECOMMENDATIONS\n",
    "# ============================================================\n",
    "\n",
    "def get_model_specific_batch_size(\n",
    "    model_name: str,\n",
    "    gpu_memory_gb: float,\n",
    "    image_size: int = 224\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Get batch size recommendation based on specific model architecture.\n",
    "    \n",
    "    These are empirically tested values for common models.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Batch size lookup table: {model: {memory_gb: batch_size}}\n",
    "    batch_size_table = {\n",
    "        'mobilenet_v2': {\n",
    "            8: 32,\n",
    "            16: 64,\n",
    "            24: 128,\n",
    "            40: 256\n",
    "        },\n",
    "        'resnet50': {\n",
    "            8: 16,\n",
    "            16: 32,\n",
    "            24: 64,\n",
    "            40: 128\n",
    "        },\n",
    "        'resnet101': {\n",
    "            8: 8,\n",
    "            16: 16,\n",
    "            24: 32,\n",
    "            40: 64\n",
    "        },\n",
    "        'efficientnet_b0': {\n",
    "            8: 32,\n",
    "            16: 64,\n",
    "            24: 128,\n",
    "            40: 256\n",
    "        },\n",
    "        'efficientnet_b4': {\n",
    "            8: 8,\n",
    "            16: 16,\n",
    "            24: 32,\n",
    "            40: 64\n",
    "        },\n",
    "        'vit_base': {\n",
    "            8: 8,\n",
    "            16: 16,\n",
    "            24: 32,\n",
    "            40: 64\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Adjust for image size (larger images need smaller batches)\n",
    "    size_multiplier = (224 / image_size) ** 2\n",
    "    \n",
    "    if model_name in batch_size_table:\n",
    "        # Find closest memory tier\n",
    "        memory_tiers = sorted(batch_size_table[model_name].keys())\n",
    "        closest_tier = min(memory_tiers, key=lambda x: abs(x - gpu_memory_gb))\n",
    "        \n",
    "        base_batch_size = batch_size_table[model_name][closest_tier]\n",
    "        adjusted_batch_size = int(base_batch_size * size_multiplier)\n",
    "        \n",
    "        # Round to nearest power of 2 for efficiency\n",
    "        return 2 ** int(np.log2(adjusted_batch_size))\n",
    "    else:\n",
    "        # Fallback to memory-based estimation\n",
    "        if gpu_memory_gb >= 40:\n",
    "            return int(128 * size_multiplier)\n",
    "        elif gpu_memory_gb >= 24:\n",
    "            return int(64 * size_multiplier)\n",
    "        elif gpu_memory_gb >= 16:\n",
    "            return int(32 * size_multiplier)\n",
    "        else:\n",
    "            return int(16 * size_multiplier)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# USAGE EXAMPLES\n",
    "# ============================================================\n",
    "\n",
    "# Basic usage\n",
    "CLUSTER_RESOURCES = detect_and_configure_resources()\n",
    "\n",
    "# Advanced: Model-specific batch size\n",
    "if CLUSTER_RESOURCES['use_gpu']:\n",
    "    model_batch_size = get_model_specific_batch_size(\n",
    "        model_name='mobilenet_v2',\n",
    "        gpu_memory_gb=CLUSTER_RESOURCES['gpu_memory_gb'],\n",
    "        image_size=224\n",
    "    )\n",
    "    print(f\"\\nModel-specific batch size recommendation: {model_batch_size}\")\n",
    "    \n",
    "    # Override default if model-specific is available\n",
    "    CLUSTER_RESOURCES['recommended_batch_size'] = model_batch_size\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# VALIDATION AND WARNINGS\n",
    "# ============================================================\n",
    "\n",
    "def validate_configuration(config: Dict) -> None:\n",
    "    \"\"\"Validate configuration and print warnings.\"\"\"\n",
    "    \n",
    "    warnings = []\n",
    "    \n",
    "    # Check batch size\n",
    "    if config['use_gpu'] and config['recommended_batch_size'] < 8:\n",
    "        warnings.append(\n",
    "            f\"Very small batch size ({config['recommended_batch_size']}) - \"\n",
    "            \"may lead to unstable training\"\n",
    "        )\n",
    "    \n",
    "    # Check num_workers\n",
    "    if config['recommended_num_workers'] == 0:\n",
    "        warnings.append(\n",
    "            \"DataLoader workers set to 0 - data loading will be synchronous (slower)\"\n",
    "        )\n",
    "    \n",
    "    # Check GPU utilization\n",
    "    if config['use_gpu']:\n",
    "        expected_memory_usage = config['recommended_batch_size'] * 4  # Rough estimate in GB\n",
    "        if expected_memory_usage > config['gpu_memory_gb'] * 0.9:\n",
    "            warnings.append(\n",
    "                f\"Batch size may be too large - estimated {expected_memory_usage:.1f}GB \"\n",
    "                f\"vs {config['gpu_memory_gb']:.1f}GB available\"\n",
    "            )\n",
    "    \n",
    "    # Check worker/GPU ratio\n",
    "    if config['use_gpu'] and config['num_gpus_per_node'] > 0:\n",
    "        workers_per_gpu = config['recommended_num_workers'] / config['num_gpus_per_node']\n",
    "        if workers_per_gpu < 2:\n",
    "            warnings.append(\n",
    "                f\"Only {workers_per_gpu:.1f} workers per GPU - may bottleneck data loading\"\n",
    "            )\n",
    "        elif workers_per_gpu > 8:\n",
    "            warnings.append(\n",
    "                f\"{workers_per_gpu:.1f} workers per GPU - may cause overhead\"\n",
    "            )\n",
    "    \n",
    "    if warnings:\n",
    "        print(f\"\\n⚠ Configuration Warnings:\")\n",
    "        for warning in warnings:\n",
    "            print(f\"  • {warning}\")\n",
    "    else:\n",
    "        print(f\"\\n✓ Configuration validated successfully\")\n",
    "\n",
    "\n",
    "# Run validation\n",
    "validate_configuration(CLUSTER_RESOURCES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "249267ad-0987-426e-b209-acfd7bf9113c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CLUSTER_RESOURCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe70e2fb-7d5a-4e76-a2a3-eeec5863051b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "e.g. apply to CONFIG"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATASET CONFIGURATION\n",
    "# ============================================================\n",
    "CATALOG = \"mmt\"\n",
    "SCHEMA = \"pytorch\"\n",
    "VOLUME_NAME = \"torch_data\"\n",
    "\n",
    "# Dataset paths\n",
    "mds_train_dir = 'imagenet_tiny200_mds_train'\n",
    "mds_val_dir = 'imagenet_tiny200_mds_val'\n",
    "data_storage_location = f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME_NAME}\"\n",
    "\n",
    "# Dataset parameters\n",
    "num_classes = 200\n",
    "num_workers = CLUSTER_RESOURCES['recommended_num_workers']  # AUTO-CONFIGURED\n",
    "\n",
    "# ============================================================\n",
    "# TRAINING CONFIGURATION (AUTO-TUNED)\n",
    "# ============================================================\n",
    "NUM_EPOCHS = 2\n",
    "N_TRIALS = 3\n",
    "\n",
    "# Batch size configuration - will be used as base for Optuna search\n",
    "BASE_BATCH_SIZE = CLUSTER_RESOURCES['recommended_batch_size']  # AUTO-CONFIGURED\n",
    "TOTAL_GPUS = CLUSTER_RESOURCES['total_gpus']  # AUTO-CONFIGURED\n",
    "\n",
    "# Effective batch size across all GPUs\n",
    "EFFECTIVE_BATCH_SIZE = BASE_BATCH_SIZE * max(TOTAL_GPUS, 1)\n",
    "\n",
    "# ============================================================\n",
    "# DISTRIBUTED TRAINING CONFIGURATION\n",
    "# ============================================================\n",
    "DISTRIBUTOR_CONFIG = {\n",
    "    'num_processes': CLUSTER_RESOURCES['distributor_num_processes'],\n",
    "    'local_mode': CLUSTER_RESOURCES['distributor_local_mode'],\n",
    "    'use_gpu': CLUSTER_RESOURCES['use_gpu']\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# CHECKPOINTING CONFIGURATION\n",
    "# ============================================================\n",
    "ENABLE_CHECKPOINTING = True\n",
    "CHECKPOINT_FREQUENCY = 1\n",
    "RESUME_FROM_CHECKPOINT = False\n",
    "\n",
    "# ============================================================\n",
    "# EXPERIMENT-SPECIFIC PATH CONFIGURATION\n",
    "# ============================================================\n",
    "import os\n",
    "from datetime import datetime\n",
    "import mlflow\n",
    "\n",
    "BASE_VOLUME_PATH = f\"/Volumes/{CATALOG}/{SCHEMA}/{VOLUME_NAME}\"\n",
    "BASE_VOLUME_DBFS = f\"dbfs:/Volumes/{CATALOG}/{SCHEMA}/{VOLUME_NAME}\"\n",
    "\n",
    "EXPERIMENT_SHORT_NAME = \"imagenet_mobilenetv2_hpt_chkpt\"\n",
    "EXPERIMENT_TIMESTAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "USER_NAME = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n",
    "EXPERIMENT_NAME = f\"/Users/{USER_NAME}/mlflow_experiments/pytorch_{EXPERIMENT_SHORT_NAME}\"\n",
    "\n",
    "EXPERIMENT_ROOT = f\"{BASE_VOLUME_PATH}/{EXPERIMENT_SHORT_NAME}\"\n",
    "EXPERIMENT_ROOT_DBFS = f\"{BASE_VOLUME_DBFS}/{EXPERIMENT_SHORT_NAME}\"\n",
    "\n",
    "CHECKPOINT_BASE_DIR = f\"{EXPERIMENT_ROOT}/checkpoints/{EXPERIMENT_TIMESTAMP}\"\n",
    "MLFLOW_ARTIFACT_LOCATION = f\"{EXPERIMENT_ROOT_DBFS}/mlflow_artifacts\"\n",
    "\n",
    "os.makedirs(CHECKPOINT_BASE_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{EXPERIMENT_ROOT}/mlflow_artifacts\", exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# MLFLOW SETUP\n",
    "# ============================================================\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "mlflow.enable_system_metrics_logging()\n",
    "\n",
    "experiment = mlflow.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment:\n",
    "    experiment_id = experiment.experiment_id\n",
    "    print(f\"✓ Reusing existing MLflow experiment\")\n",
    "    print(f\"  Name: {EXPERIMENT_NAME}\")\n",
    "    print(f\"  Experiment ID: {experiment_id}\")\n",
    "    MLFLOW_ARTIFACT_LOCATION = experiment.artifact_location\n",
    "else:\n",
    "    experiment_id = mlflow.create_experiment(\n",
    "        name=EXPERIMENT_NAME,\n",
    "        artifact_location=MLFLOW_ARTIFACT_LOCATION\n",
    "    )\n",
    "    experiment = mlflow.get_experiment(experiment_id)\n",
    "    print(f\"✓ Created new MLflow experiment\")\n",
    "    print(f\"  Name: {EXPERIMENT_NAME}\")\n",
    "    print(f\"  Experiment ID: {experiment_id}\")\n",
    "\n",
    "mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION SUMMARY\n",
    "# ============================================================\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"CLUSTER RESOURCE CONFIGURATION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Cluster Size:\")\n",
    "print(f\"  Total Nodes:          {CLUSTER_RESOURCES['total_nodes']} ({CLUSTER_RESOURCES['num_workers']} workers + 1 driver)\")\n",
    "print(f\"  GPUs per Node:        {CLUSTER_RESOURCES['num_gpus_per_node']}\")\n",
    "print(f\"  Total GPUs:           {CLUSTER_RESOURCES['total_gpus']}\")\n",
    "print(f\"  CUDA Available:       {CLUSTER_RESOURCES['cuda_available']}\")\n",
    "print(f\"\\nDistributed Training:\")\n",
    "print(f\"  num_processes:        {DISTRIBUTOR_CONFIG['num_processes']}\")\n",
    "print(f\"  local_mode:           {DISTRIBUTOR_CONFIG['local_mode']}\")\n",
    "print(f\"  use_gpu:              {DISTRIBUTOR_CONFIG['use_gpu']}\")\n",
    "print(f\"\\nAuto-Configured Parameters:\")\n",
    "print(f\"  Base Batch Size:      {BASE_BATCH_SIZE} (per GPU)\")\n",
    "print(f\"  Effective Batch Size: {EFFECTIVE_BATCH_SIZE} (total across {max(TOTAL_GPUS, 1)} GPUs)\")\n",
    "print(f\"  Dataloader Workers:   {num_workers} (per process)\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"EXPERIMENT CONFIGURATION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Experiment: {EXPERIMENT_SHORT_NAME}\")\n",
    "print(f\"Timestamp:  {EXPERIMENT_TIMESTAMP}\")\n",
    "print(f\"\\nDataset Configuration:\")\n",
    "print(f\"  Storage Location: {data_storage_location}\")\n",
    "print(f\"  Training Data:    {data_storage_location}/{mds_train_dir}\")\n",
    "print(f\"  Validation Data:  {data_storage_location}/{mds_val_dir}\")\n",
    "print(f\"  Num Classes:      {num_classes}\")\n",
    "print(f\"\\nDirectory Structure:\")\n",
    "print(f\"  Root: {EXPERIMENT_ROOT}/\")\n",
    "print(f\"  ├── checkpoints/\")\n",
    "print(f\"  │   └── {EXPERIMENT_TIMESTAMP}/\")\n",
    "print(f\"  └── mlflow_artifacts/\")\n",
    "print(f\"\\nPaths:\")\n",
    "print(f\"  Experiment Root:     {EXPERIMENT_ROOT}\")\n",
    "print(f\"  Checkpoint Base:     {CHECKPOINT_BASE_DIR}\")\n",
    "print(f\"  MLflow Artifacts:    {MLFLOW_ARTIFACT_LOCATION}\")\n",
    "print(f\"  MLflow Experiment:   {EXPERIMENT_NAME}\")\n",
    "print(f\"  Experiment ID:       {experiment_id}\")\n",
    "print(f\"\\nTraining Configuration:\")\n",
    "print(f\"  Num Classes:      {num_classes}\")\n",
    "print(f\"  Num Epochs:       {NUM_EPOCHS}\")\n",
    "print(f\"  Num Trials:       {N_TRIALS}\")\n",
    "print(f\"  Checkpointing:    {ENABLE_CHECKPOINTING}\")\n",
    "print(f\"  Checkpoint Freq:  {CHECKPOINT_FREQUENCY}\")\n",
    "print(f\"  Resume Enabled:   {RESUME_FROM_CHECKPOINT}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY PATHS\n",
    "# ============================================================\n",
    "print(\"Verifying paths...\")\n",
    "assert os.path.exists(data_storage_location), f\"Data storage location not found: {data_storage_location}\"\n",
    "assert os.path.exists(f\"{data_storage_location}/{mds_train_dir}\"), f\"Training data not found\"\n",
    "assert os.path.exists(f\"{data_storage_location}/{mds_val_dir}\"), f\"Validation data not found\"\n",
    "assert os.path.exists(CHECKPOINT_BASE_DIR), f\"Checkpoint directory not created\"\n",
    "assert os.path.exists(f\"{EXPERIMENT_ROOT}/mlflow_artifacts\"), f\"MLflow artifacts directory not created\"\n",
    "print(\"✓ All paths verified\")\n",
    "print(f\"  ✓ Training data: {len(os.listdir(f'{data_storage_location}/{mds_train_dir}'))} files\")\n",
    "print(f\"  ✓ Validation data: {len(os.listdir(f'{data_storage_location}/{mds_val_dir}'))} files\")\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# OPTUNA HYPERPARAMETER SEARCH SPACE (BATCH SIZE AWARE)\n",
    "# ============================================================\n",
    "def get_optuna_search_space(trial):\n",
    "    \"\"\"Define search space with batch size scaled to cluster resources.\"\"\"\n",
    "    return {\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True),\n",
    "        'weight_decay': trial.suggest_float('weight_decay', 1e-5, 1e-3, log=True),\n",
    "        'dropout_rate': trial.suggest_float('dropout_rate', 0.1, 0.5),\n",
    "        # Batch size suggestions scaled to BASE_BATCH_SIZE\n",
    "        'batch_size': trial.suggest_categorical('batch_size', \n",
    "            [BASE_BATCH_SIZE // 2, BASE_BATCH_SIZE, BASE_BATCH_SIZE * 2]\n",
    "        ),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['adam', 'adamw', 'sgd'])\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# GLOBAL VARIABLES\n",
    "# ============================================================\n",
    "EXPERIMENT_RUN_ID = None\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"READY TO START OPTIMIZATION\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Configuration complete. Run the optimization cell to begin training.\")\n",
    "print(f\"Use DISTRIBUTOR_CONFIG for TorchDistributor initialization.\")\n",
    "print(f\"Use BASE_BATCH_SIZE as reference for Optuna batch size search.\")\n",
    "print(f\"{'='*80}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5df8b914-9954-4ea9-9fd9-c9cfa2f1fef8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# **Example Integration -- [!!] subject to data-model-training testing:**\n",
    "\n",
    "# 1. **Auto-configured `num_workers`**: Set based on GPU count (4 per GPU, capped at 8)\n",
    "# 2. **Auto-configured `BASE_BATCH_SIZE`**: Based on GPU memory detection\n",
    "# 3. **`DISTRIBUTOR_CONFIG`**: Ready-to-use dictionary for TorchDistributor\n",
    "# 4. **`EFFECTIVE_BATCH_SIZE`**: Total batch size across all GPUs for monitoring\n",
    "\n",
    "# **Usage in your training function:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9512e473-d007-4794-a0a3-5f5c591aa92a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DISTRIBUTOR_CONFIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a8a7c5f-4c18-4059-b820-8754b61dbd37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**NOTES:**\n",
    "\n",
    "References:   \n",
    "\n",
    "Batch Size Scaling:  \n",
    "Goyal et al. (2017) - \"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\"    \n",
    "Smith et al. (2017) - \"Don't Decay the Learning Rate, Increase the Batch Size\"    \n",
    "\n",
    "Model-Specific:   \n",
    "He et al. (2015) - ResNet paper (batch 256 across 8 GPUs)    \n",
    "Sandler et al. (2018) - MobileNetV2 (batch 96 on TPUs)   \n",
    "Tan & Le (2019) - EfficientNet (batch 2048 on TPUs)   \n",
    "\n",
    "Practical Implementations:   \n",
    "PyTorch ImageNet examples: https://github.com/pytorch/examples/tree/main/imagenet   \n",
    "TorchVision training reference: https://github.com/pytorch/vision/tree/main/references/classification    \n",
    "\n",
    "**General Heuristics** \n",
    "- Start with literature values if available\n",
    "- Run find_max_batch_size() empirically (most reliable)\n",
    "- Use Optuna to tune around that value\n",
    "- Monitor GPU utilization and adjust\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "test_resource_detect_v0.1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
